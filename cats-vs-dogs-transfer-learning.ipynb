{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom os import listdir\nimport shutil\nimport zipfile\nimport tensorflow as tf\n\nfrom keras.layers import Dense, Activation, Flatten, Dropout\nfrom keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import SGD, Adam\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-05T19:55:46.934378Z","iopub.execute_input":"2022-04-05T19:55:46.935166Z","iopub.status.idle":"2022-04-05T19:55:52.422962Z","shell.execute_reply.started":"2022-04-05T19:55:46.935066Z","shell.execute_reply":"2022-04-05T19:55:52.4222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_zip='/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip'\nzip_ref=zipfile.ZipFile(train_zip,'r')\nzip_ref.extractall('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T19:56:07.809632Z","iopub.execute_input":"2022-04-05T19:56:07.810209Z","iopub.status.idle":"2022-04-05T19:56:20.044848Z","shell.execute_reply.started":"2022-04-05T19:56:07.810166Z","shell.execute_reply":"2022-04-05T19:56:20.044049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nwork='/kaggle/working'\ntrain_path='/kaggle/working/train/'\nfile_items=os.listdir(train_path)\n\nfig,([ax1,ax2,ax3,ax4,ax5],[ax6,ax7,ax8,ax9,ax10])=plt.subplots(2,5,figsize=(15,10))\nfigs=[ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9,ax10]\n\nfor i in range(10):\n    k=mpimg.imread(os.path.join(train_path,file_items[i]))\n    figs[i].imshow(k)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T19:56:20.048023Z","iopub.execute_input":"2022-04-05T19:56:20.04872Z","iopub.status.idle":"2022-04-05T19:56:21.357201Z","shell.execute_reply.started":"2022-04-05T19:56:20.048681Z","shell.execute_reply":"2022-04-05T19:56:21.355035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir '/kaggle/working/train/dog'\n!mkdir '/kaggle/working/train/cat'","metadata":{"execution":{"iopub.status.busy":"2022-04-05T19:56:21.3583Z","iopub.execute_input":"2022-04-05T19:56:21.358557Z","iopub.status.idle":"2022-04-05T19:56:22.712657Z","shell.execute_reply.started":"2022-04-05T19:56:21.358522Z","shell.execute_reply":"2022-04-05T19:56:22.71167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor f in listdir(train_path):\n    if os.path.isfile(os.path.join(train_path, f)):\n        if \"dog\" in f:\n            shutil.move(os.path.join(train_path, f), os.path.join('/kaggle/working/train/dog', f))\n        if \"cat\" in f:\n            shutil.move(os.path.join(train_path, f), os.path.join('/kaggle/working/train/cat', f))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T19:56:22.715626Z","iopub.execute_input":"2022-04-05T19:56:22.716214Z","iopub.status.idle":"2022-04-05T19:56:23.57166Z","shell.execute_reply.started":"2022-04-05T19:56:22.716167Z","shell.execute_reply":"2022-04-05T19:56:23.570853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dog_train_path='/kaggle/working/train/dog'\ncat_train_path='/kaggle/working/train/cat'","metadata":{"execution":{"iopub.status.busy":"2022-04-05T19:56:23.572943Z","iopub.execute_input":"2022-04-05T19:56:23.573272Z","iopub.status.idle":"2022-04-05T19:56:23.57811Z","shell.execute_reply.started":"2022-04-05T19:56:23.573236Z","shell.execute_reply":"2022-04-05T19:56:23.577254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model = tf.keras.applications.resnet50.ResNet50(weights='imagenet', \n                      include_top=False, \n                      input_shape=(224, 224, 3))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T19:56:25.912642Z","iopub.execute_input":"2022-04-05T19:56:25.914864Z","iopub.status.idle":"2022-04-05T19:56:30.904364Z","shell.execute_reply.started":"2022-04-05T19:56:25.914811Z","shell.execute_reply":"2022-04-05T19:56:30.903529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_dir = \"/kaggle/working/train\"\nBATCH_SIZE = 8\n\ntrain_datagen =  tf.keras.preprocessing.image.ImageDataGenerator(\n      preprocessing_function= tf.keras.applications.resnet50.preprocess_input,\n      rotation_range=90,\n      horizontal_flip=True,\n      vertical_flip=True,shear_range=0.2,\n    zoom_range=0.1,\n    validation_split=0.05\n    )\n\ntrain_generator = train_datagen.flow_from_directory(train_dir, \n                                                    target_size=(200, 200), \n                                                    batch_size=BATCH_SIZE,\n    subset='training', class_mode='binary'\n                                                   )\n\nvalidation_generator = train_datagen.flow_from_directory(train_dir, \n                                                    target_size=(200, 200), \n                                                    batch_size=BATCH_SIZE, subset='validation', class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T20:58:07.120335Z","iopub.execute_input":"2022-04-05T20:58:07.120705Z","iopub.status.idle":"2022-04-05T20:58:07.895001Z","shell.execute_reply.started":"2022-04-05T20:58:07.120671Z","shell.execute_reply":"2022-04-05T20:58:07.89416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_zip='/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip'\nzip_ref=zipfile.ZipFile(train_zip,'r')\nzip_ref.extractall('/kaggle/test/')\ntest_datagen =  tf.keras.preprocessing.image.ImageDataGenerator(\n      preprocessing_function= tf.keras.applications.resnet50.preprocess_input\n    )\n\ntest_datagen = test_datagen.flow_from_directory('/kaggle/test/', \n                                                    target_size=(200, 200), \n                                                    batch_size=32,shuffle = False)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T19:56:31.80638Z","iopub.execute_input":"2022-04-05T19:56:31.806647Z","iopub.status.idle":"2022-04-05T19:56:39.256885Z","shell.execute_reply.started":"2022-04-05T19:56:31.806611Z","shell.execute_reply":"2022-04-05T19:56:39.256085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training the Resnet model with one FC hidden layer","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(tf.keras.applications.resnet50.ResNet50(include_top = False, pooling = 'max', weights = 'imagenet'))\nmodel.add(Dense(10, activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\n\nmodel.layers[0].trainable = False \nmodel.compile(optimizer = 'adam', metrics = ['accuracy'], loss = 'binary_crossentropy')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T19:56:39.258508Z","iopub.execute_input":"2022-04-05T19:56:39.259349Z","iopub.status.idle":"2022-04-05T19:56:41.235851Z","shell.execute_reply.started":"2022-04-05T19:56:39.259297Z","shell.execute_reply":"2022-04-05T19:56:41.234795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(train_generator, epochs = 5, validation_data = validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T19:58:05.816351Z","iopub.execute_input":"2022-04-05T19:58:05.816639Z","iopub.status.idle":"2022-04-05T20:23:13.886592Z","shell.execute_reply.started":"2022-04-05T19:58:05.816603Z","shell.execute_reply":"2022-04-05T20:23:13.885868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.history\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T20:24:54.934807Z","iopub.execute_input":"2022-04-05T20:24:54.935143Z","iopub.status.idle":"2022-04-05T20:24:55.277537Z","shell.execute_reply.started":"2022-04-05T20:24:54.935101Z","shell.execute_reply":"2022-04-05T20:24:55.27682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(test_datagen)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:28:35.287197Z","iopub.execute_input":"2022-04-05T03:28:35.287816Z","iopub.status.idle":"2022-04-05T03:29:16.369937Z","shell.execute_reply.started":"2022-04-05T03:28:35.287774Z","shell.execute_reply":"2022-04-05T03:29:16.369081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submitting the below file which gave loss score of 0.075","metadata":{}},{"cell_type":"code","source":"files = [f.split('.')[0][5:] for f in test_datagen.filenames]\nsolution = pd.DataFrame({\"id\": files, \"label\":pred[:,0]})\nsolution.to_csv(\"dogsVScatsRes3.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T03:29:48.194302Z","iopub.execute_input":"2022-04-05T03:29:48.194968Z","iopub.status.idle":"2022-04-05T03:29:48.238227Z","shell.execute_reply.started":"2022-04-05T03:29:48.194927Z","shell.execute_reply":"2022-04-05T03:29:48.237498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","metadata":{"execution":{"iopub.status.busy":"2022-04-05T17:24:13.077233Z","iopub.execute_input":"2022-04-05T17:24:13.077503Z","iopub.status.idle":"2022-04-05T17:24:13.081449Z","shell.execute_reply.started":"2022-04-05T17:24:13.077474Z","shell.execute_reply":"2022-04-05T17:24:13.08058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ensemble model with VGG19 InceptionV3 and resnet","metadata":{}},{"cell_type":"code","source":"vgg = tf.keras.applications.vgg19.VGG19(weights='imagenet',\n                  include_top=False,\n                  input_shape=(224, 224, 3),pooling=\"max\")\n\nfor layers in vgg.layers:\n    layers.trainable=False\n\nprint(vgg.output)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T17:32:26.312827Z","iopub.execute_input":"2022-04-05T17:32:26.313131Z","iopub.status.idle":"2022-04-05T17:32:27.507878Z","shell.execute_reply.started":"2022-04-05T17:32:26.313101Z","shell.execute_reply":"2022-04-05T17:32:27.507112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inc = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet',\n                  include_top=False,\n                  input_shape=(224, 224, 3),pooling=\"max\")\n\nfor layers in inc.layers:\n    layers.trainable=False\n\nprint(inc.output)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T17:23:28.474518Z","iopub.execute_input":"2022-04-05T17:23:28.475308Z","iopub.status.idle":"2022-04-05T17:23:31.622336Z","shell.execute_reply.started":"2022-04-05T17:23:28.475268Z","shell.execute_reply":"2022-04-05T17:23:31.620755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_list = []\ny=[]\nfor path in listdir(dog_train_path):\n    x = load_img(dog_train_path+'/'+path,target_size=(224,224))\n    img_array = img_to_array(x)\n    img_array = np.expand_dims(img_array, axis=0)\n    features = vgg.predict(img_array)\n    feature_list.append(features)\n    \nfeat_lst = np.reshape(feature_list,(-1,7*7*512))\ny=[1]*feat_lst.shape[0]\nfeature_list = []\nfor path in listdir(cat_train_path):\n    x = load_img(cat_train_path+'/'+path,target_size=(224,224))\n    img_array = img_to_array(x)\n    img_array = np.expand_dims(img_array, axis=0)\n    features = vgg.predict(img_array)\n    feature_list.append(features)\n    \nfeat_lst = np.append(feat_lst ,np.reshape(feature_list,(-1,7*7*512)), axis=0)\ny=y+[0]*feat_lst.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-04-04T19:05:32.774569Z","iopub.status.idle":"2022-04-04T19:05:32.775109Z","shell.execute_reply.started":"2022-04-04T19:05:32.774873Z","shell.execute_reply":"2022-04-04T19:05:32.774899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fs= [dog_train_path+'/'+path for path in listdir(dog_train_path)] + [cat_train_path+'/'+path for path in listdir(cat_train_path)]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T17:24:17.767392Z","iopub.execute_input":"2022-04-05T17:24:17.767978Z","iopub.status.idle":"2022-04-05T17:24:17.792859Z","shell.execute_reply.started":"2022-04-05T17:24:17.767939Z","shell.execute_reply":"2022-04-05T17:24:17.79219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resent = tf.keras.applications.resnet50.ResNet50(include_top = False, pooling = 'max', weights = 'imagenet')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T17:24:34.031774Z","iopub.execute_input":"2022-04-05T17:24:34.032325Z","iopub.status.idle":"2022-04-05T17:24:36.940751Z","shell.execute_reply.started":"2022-04-05T17:24:34.032284Z","shell.execute_reply":"2022-04-05T17:24:36.937384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=[]\nfeature_list = []\nfor path in fs:\n    x = load_img(path,target_size=(224,224))\n    img_array = img_to_array(x)\n    img_array = np.expand_dims(img_array, axis=0)\n    feature_list.append(np.concatenate([resent.predict(img_array)[0],inc.predict(img_array)[0],vgg.predict(img_array)[0]]))\n    y.append(1 if 'dog' in path else 0)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T17:33:09.40925Z","iopub.execute_input":"2022-04-05T17:33:09.409522Z","iopub.status.idle":"2022-04-05T18:34:10.39257Z","shell.execute_reply.started":"2022-04-05T17:33:09.409485Z","shell.execute_reply":"2022-04-05T18:34:10.391816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\ninput_file = open(\"resent.pkl\",'wb')\npickle.dump({\"x\":feature_list,'y':y},input_file)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T18:36:11.78066Z","iopub.execute_input":"2022-04-05T18:36:11.780914Z","iopub.status.idle":"2022-04-05T18:36:12.861661Z","shell.execute_reply.started":"2022-04-05T18:36:11.780887Z","shell.execute_reply":"2022-04-05T18:36:12.860906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\ninput_file = open(\"/kaggle/input/resenet1/resent (1).pkl\",'rb')\ndb = pickle.load(input_file)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T20:35:52.41341Z","iopub.execute_input":"2022-04-05T20:35:52.413683Z","iopub.status.idle":"2022-04-05T20:35:57.082005Z","shell.execute_reply.started":"2022-04-05T20:35:52.413649Z","shell.execute_reply":"2022-04-05T20:35:57.081201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(db['x'], db['y'], test_size=0.10, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T20:36:06.753232Z","iopub.execute_input":"2022-04-05T20:36:06.753499Z","iopub.status.idle":"2022-04-05T20:36:07.361921Z","shell.execute_reply.started":"2022-04-05T20:36:06.753468Z","shell.execute_reply":"2022-04-05T20:36:07.361139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training a lighgbm model ","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nclf = lgb.LGBMClassifier()\nclf.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T20:36:12.270292Z","iopub.execute_input":"2022-04-05T20:36:12.271171Z","iopub.status.idle":"2022-04-05T20:38:25.88343Z","shell.execute_reply.started":"2022-04-05T20:36:12.271116Z","shell.execute_reply":"2022-04-05T20:38:25.882658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\ny_pred=clf.predict(X_test)\nprint(classification_report(y_test,y_pred ))\ncm = confusion_matrix(y_test, y_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm)\ndisp.plot()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T20:41:54.858889Z","iopub.execute_input":"2022-04-05T20:41:54.859177Z","iopub.status.idle":"2022-04-05T20:41:55.165096Z","shell.execute_reply.started":"2022-04-05T20:41:54.859144Z","shell.execute_reply":"2022-04-05T20:41:55.16439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = []\nfiles=[]\ntestpath = '/kaggle/test/test'\nfor path in listdir(testpath):\n    files.append(path)\n    x = load_img(testpath+'/'+path,target_size=(224,224))\n    img_array = img_to_array(x)\n    img_array = np.expand_dims(img_array, axis=0)\n    pred.append(clf.predict_proba([np.concatenate([resent.predict(img_array)[0],inc.predict(img_array)[0],vgg.predict(img_array)[0]])]))","metadata":{"execution":{"iopub.status.busy":"2022-04-05T18:48:37.351903Z","iopub.execute_input":"2022-04-05T18:48:37.352397Z","iopub.status.idle":"2022-04-05T19:19:40.189019Z","shell.execute_reply.started":"2022-04-05T18:48:37.352359Z","shell.execute_reply":"2022-04-05T19:19:40.188418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The below file gave loss of 0.078","metadata":{}},{"cell_type":"code","source":"files = [f.split('.')[0] for f in files]\nsolution2 = pd.DataFrame({\"id\": files, \"label\":np.array(pred).reshape(12500,2)[:,1]})\nsolution2.to_csv(\"dogsVScats.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T19:21:21.251647Z","iopub.execute_input":"2022-04-05T19:21:21.252387Z","iopub.status.idle":"2022-04-05T19:21:21.328508Z","shell.execute_reply.started":"2022-04-05T19:21:21.25235Z","shell.execute_reply":"2022-04-05T19:21:21.327757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"FInal submission is avg of both scores which gave loss of 0.068","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"References:\nhttps://www.kaggle.com/code/sanchitvj/cat-or-dog-transfer-learning-using-resnets\nhttps://towardsdatascience.com/transfer-learning-for-image-classification-using-keras-c47ccf09c8c8","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}